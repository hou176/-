# 数据分析和挖掘常用方法
聚类分析  回归分析  分类分析  常用分析手段

### 不同方法内在业务联系

- 聚类分析
	- 用户是那些群体组成的
	- 这些群体有那些明显的特征
- 回归分析
	- 未来销售趋势预测
	- 营销投入如何影响销售
- 分类分析
	- 筛选出更值得营销的用户
- 其他分析手段
	- 关联分析
	- 异常检测分析

### 聚类分析

- 聚类就是把相似特征的划分一个类别  经常用于数据探索和挖掘前期  没有之前经验的背景下  也是用与样本量比较大的时候
- 常用语客户分群 目的就是为了用户分组组内用户特征显示  不用组用户特征差异明显
- 客户分群的数据维度：行为习惯数据  对产品态度  自身的人口统计学特征  顾客消费的行为的度量（rfm）等数据
- 聚类分析能解决的问题
	- 数据集分为几类
	- 每个类别有多少样本
	- 不用类别中各个变量的强弱关系如何
	- 不同类别的典型特征是什么
- 基于聚类的客户分群  能帮助我们更清楚的人事客户
	- 凭借经验和限制数据人事客户是很模糊的
	- 采用聚类方法明确区分了不同客户特征 对用户的认识清晰 
	对客户有清晰的认识：1.可以为不同客户群提供定制化的产品或者服务 2.设定品牌的主要形象地位 3. 根据顾客需求 挖掘新的产品和服务的机会  有一个旅游类的APP 利用以往数据对不用客户的差异化运营策略从 针对性的指定旅游产品
- 聚类非常注重落地效果
	-聚类后用户分群有明显特征
	-聚类用户分群有足够的用户
	- 分群之后用户是否能触达  结果必须要可操作 如果用户不触达 没联系  也没有意义了
	- 做好用户分群需要充分的用户信息  累积对自己有用的有效客户信息
- 聚类是要注意的问题
	- k均值（k-means） 聚类中常见的方法  基于点与点距离的相似度来计算最佳类别对数  但是k均值在应用之前一定注意两种数据异常  1.（就算是极大值极小值这样的，在散点图中因为他有问题，一般就是数据处理好的）异常值能明显改变不同点距离的相似度  并且可能是非常显著的  异常值处理是不可少的
	2.数据的异常量纲 不通维度变量之间  存在数据规模或者是异常量纲差异 那么做距离之前需要行将变量归一化标准化  比如数值区间1,0 金额可能是1,100000000000  数量是1,1000  相似度肯定是要收到金额影响的
	- 数量过大时候不适合用k-means  算法稳定性、效率、准确率表现非常好对大量的数据时候也是这样  算法时间复杂度能承受 n*k*t   样本量*聚类数*迭代次数  聚类数迭代不变时  k均值消耗时间就跟样本量有关 一次会呈线性增长趋势 面对海量数据时候面临严重的结果延迟  尤其是当k均值被用作实时性或者准时性的数据预处理 分析和建模时候  这种瓶颈很明显
	- 解决k-means这个问题出现了迷你Barchkmeans 它好处是不用使用所有的数据了 而是在不同类别里面抽取一部分样本  而非全部样本  

### 回归分析

- 最简单的回归模型是一元线性回归  表示为Y=β0+β1x+ε  其中Y为**因变量**，x为自变量，β1为影响系数，β0为截距，ε为随机误差。**很想方程式**
- 回归分析**是常用的统计分析方法** 可用于分析自变量和因变量的影响关系  也可以分析自变量对因变量的影响方向（正影响还是负影响）
- 回归分析主要的应用场景是进行预测和控制计划制定  KPI制定  目标制定 也可以基于预测的数据预实际数据进行对比和分析  确定时间的发展并给未来的提供方向性指导
- 常见的回归算法包括线性回归  多项式回归等
- 回归分析的有点是数据模型和结果便于了解  线性回归  y = ax+b形式表达 在解释和理解自变量的与因变量关系相对容易  基于函数的业务直接套用就可以  用起来很容易
- 回归分析只能分析少量变量之间的关系  无法处理变量之间的相互作用关系  尤其是变量共同因素对因变量的影响程度
- 回归分析的场景
	- 投放的广告对最终的销售所产生的效果研究
		- 投广告的营销渠道
		- 回答出1.各个营销渠道如何互相营销促进销售2.如何调整营销组合使每一份支出获取最大收益3.同时在不同渠道进行广告营销，哪个效果更明显
		- 营销量 = 营销变量 + 误差因素
		- 营销变量和销售变量之间是线性关系
		- 回归分析模型：销售额 =93765+0.3* 百度+0.15 * 社交媒体+0.05 *电话直销+0.02 * 短信
	- 回归分析的结果，着重于不同X对于Y影响的对比，直接预测Y的场景较少
- 回归分析的分析流程
	- 数据概况分析   单边量分析（金融风控里面）    相关性分析与可视化  回归模型的建立
- 在结果出来时候要注意应用模型是研究自变量是否从产生了变化
	- 是否产生了新的因变量影响更大的自变量  也就是遗漏变量模型肯定是不能反映问题的  而且参数还有偏的
	- 也需要重新评估问题的发生   比如正常买的但是现在做活动了 没有纳入模型中  原来的回归模型无法有效的预测
	- 还有就是自变量控制在可控范围内  不能说是1000内的预测来个变量2000

- 回归算法按照自变量分为一元和多元  按照线性分为非线性   和线性
	- 入门的开始——简单线性回归。如果是学习为主，那么不需要选择多么强大的模型，基于最小二乘法的普通线性回归最合适；同时，它适合数据集本身结构简单、分布规律有明显线性关系的场景。
	- 如果自变量数量少或经过降维后得到了可以使用的二维变量（包括预测变量），那么可以直接通过散点图发现自变量和因变量的相互关系，然后选择最佳回归方法。
	- 如果经过基本判断发现自变量间有较强的共线性关系，那么可以使用对多重共线性（自变量高度相关）能灵活处理的算法，例如岭回归。
	- 如果在高维度变量下，使用正则化回归方法效果更好，例如Lasso、Ridge
	- 如果要同时验证多个算法，并想从中选择一个来做好的拟合，可以使用交叉检验做多个模型的效果对比，并通过R-square、Adjusted R-square、AIC、BIC以及各种残差、误差项指标做综合评估。
	- 如果注重模型的可解释性，那么容易理解的线性回归、多项式回归比较适合。


### 分类分析
- 分类算法通过对已知类别训练集的计算和分析 - 从中发现类别规则并预测新数据的类别。分类算法是解决分类问题的方法，是数据挖掘、机器学习和模式识别中一个重要的研究领域。分类和回归是解决实际运营问题中非常重要的两种分析和挖掘方法。
- 常用的分类算法包括朴素贝叶斯、逻辑回归、决策树、随机森林、支持向量机等。
- 分类的主要用途和场景是“预测”，基于已有的样本预测新样本的所属类别，例如信用评级、风险等级、欺诈预测等。分类算法也可以用于知识抽取，通过模型找到潜在的规律，帮助业务得到可执行的规则。


